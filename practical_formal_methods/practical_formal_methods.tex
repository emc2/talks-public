\documentclass{beamer}
\usepackage{MnSymbol}
\usepackage{listings}

\title{Combining Formal Methods and Industrial Pragmatics}
\author{Eric L. McCorkle}

\newcommand{\typekw}[1]{\ensuremath{{\operatorname{type}}_{#1}}}
\newcommand{\propkw}{\ensuremath{\operatorname{prop}}}
\newcommand{\truthkw}{\ensuremath{\operatorname{truth}}}

\begin{document}
\begin{frame}
  \titlepage
\end{frame}

\begin{frame}
  \frametitle{My Background and Motivations}
  \begin{itemize}
    \item Started out as a systems/kernel hacker, got interested in
      compilers
    \item Interest in formal methods started as a side-effect of work on
      lock-free algorithms
    \item Started studying programming language semantics,
      mathematical foundations
    \item Worked in Java Platform Group at Oracle, saw realities of
      enterprise-scale industrial programming
    \item Moved into infosec to work on better static analysis
    \item I believe formal methods can make a huge impact if it draws
      on pragmatic knowledge from industrial practice, systems
      programming, and information security
  \end{itemize}
\end{frame}

\section{Motivation}

\begin{frame}
  \frametitle{Table of Contents}
  \tableofcontents[currentsection]
\end{frame}

\begin{frame}
  \frametitle{The Information Security Problem}
  \begin{itemize}
    \item 2014 saw a number of high-profile critical vulnerabilities;
      2015 made 2014 look like a vacation; 2016 showed very serious
      impacts of breaches
    \item Infrastructure increasingly under attack
    \item Attacks growing more sophisticated (state-sponsored)
    \item Languages and tools are a significant part of the problem
    \item \emph{Build security in} is a powerful philosophy
    \item Formal methods and verification are the language and tools
      embodiment of ``building security in''
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Difficulty of Increasing Computing Power}
  \begin{itemize}
    \item In the Good Old Days, clocks doubled every 18 months, nobody
      cared about memory bandwidth, parallelism, etc
    \item In 2004, the party started to end: Intel shifted from faster
      clocks to more cores
    \item Concurrency proved to be very difficult to manage
    \item CPU topologies becoming increasingly important
    \item FPGA's, ASICs, custom hardware
    \item If concurrency is hard, hardware is worse
    \item Takeaway: continuing to increase available computing power
      involves increasingly difficult programming models
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Engineering Methodologies}
  \begin{itemize}
    \item Mature engineering disciplines have tools for specifying and
      reasoning about the artifacts they produce
    \item Bridge, airplane, etc. designs undergo rigorous evaluation
      before construction
    \item Specify needs, then design/build to meet specifications
    \item Massive savings in time, resources, labor
    \item Software engineering could benefit from this as well
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Software Lifecycle Inefficiencies}
  \begin{itemize}
    \item Gap between design/specification and code (exact specs are
      tedious to write and maintain)
    \item Existing languages typically lack good facilities for
      reasoning about code
    \item Conventional testing generally can't achieve total coverage
    \item Even high coverage can involve large test-to-code ratios
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Making Formal Methods Practical}

  These are all problems that formal methods techniques can address.

  Hypothesis: the field of formal methods has advanced to the point
  where they can adequately address most problems in industrial-scale
  software development; however, an effort is needed to make them
  accessible and practical for industrial use.
\end{frame}

\section{Industrial Pragmatics}

\begin{frame}
  \frametitle{Table of Contents}
  \tableofcontents[currentsection]
\end{frame}

\begin{frame}
  \frametitle{Realities of Industrial Software Development}
  \begin{itemize}
    \item Golden Rule: path of least eventual cost (or pain)
    \item Scarcity: limited resources, cost/benefit tradeoffs, ROI
    \item Entropy: Bit-rot, refactoring, code evolution over time
    \item Human Factors: Large staff, varied skill levels, staff turnover
    \item Inelegance: Configurability, complex interfaces,
      customizations, irreducable complexity
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Industrial Languages: What Works?}
  \begin{itemize}
    \item Optimize for the path of least eventual cost
    \item ``Harm-reduction'' better than decrees
    \item Make it easy to do the right thing, hard to do the bad thing
    \item Code organization features: modularization, separation of
      concerns, code reusability, separate interfaces from
      implementations
    \item Present difficult ideas in a way that makes them accessible
    \item The art of API design
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Practicality Challenges for Formal Methods}
  \begin{itemize}
    \item Present verification capabilities as a benefit or a tool,
      not a demand
    \item Deal with realities of limited resources, diminishing
      returns, and ROI of proving things correct
    \item \emph{How do we organize and maintain large bodies of
      verified code and proofs?}
    \item What does ``object-oriented (or typeclasses) for proofs''
      look like?
    \item Create a truly practical proof automation system that
      working programmers can use
    \item What are the good design patterns for verified code?  What
      are the anti-patterns?
    \item Apply the art of API design to proof libraries
  \end{itemize}
\end{frame}

\section{Pay-as-You-Go}

\begin{frame}
  \frametitle{Table of Contents}
  \tableofcontents[currentsection]
\end{frame}

\begin{frame}
  \frametitle{The Need for Gradualism}

  Demanding that a program be proven correct before it can be run is
  unacceptable for industrial use.
  \begin{itemize}
    \item Ignores realities of limited resources and diminishing returns
    \item Some parts of a program are more critical than others
      (crypto, auth, control logic vs. logging, XML parser/generator)
    \item Some kinds of programs or libraries may be very difficult to verify
    \item Prototyping efforts, demos, etc
    \item Humans don't write code that way
    \item Can't eliminate testing (need to check the spec)
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{New Paradigms}
  \begin{itemize}
    \item View dependent types as a reasoning system built into the language
    \item View verification as a quality practice (total coverage at
      high up-front cost)
    \item Start with crude/no spec, no verification, refine over time
    \item Refinement of spec develops more detailed descriptions of behavior
    \item Verify critical components, then work outwards
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Verification as as Quality Practice}
  Verification fits on a continuum with existing quality practices
  \begin{itemize}
    \item Smoke-tests: one-off tests- very low fidelity, minimal cost
    \item Regression suites: tests against historical failures- low
      cost, low quality
    \item Unit/System tests: engineered test suites- mid cost, can
      achieve reasonable fidelity
    \item Enumeration/Randomized Stress-Tests: tools built to
      automatically generate huge numbers of test cases- high cost,
      high fidelity
    \item Verification: proving implementation obeys spec- high
      up-front cost, total coverage
  \end{itemize}
  But you still need to test the spec!
\end{frame}

\begin{frame}
  \frametitle{Gradual Proof-Checking}
  Support gradualism with a two-stage type/proof-checking architecture:
  \begin{itemize}
    \item Stage 1 is (decidable) type-checking, provides guarantees on
      the level of Hindley-Milner/Haskell/Java/etc
    \item Type-checking produces a set of proof obligations as an artifacts
    \item Stage 2 is (undecidable) proof-checking, discharges proof
      obligations
    \item Can compile and run if stage 1 passes
    \item If we discharge all proof obligations, the program is
      ``safe'' (check the spec!)
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Other Uses of Proof Obligations}

  We can do other things with proof obligations besides prove them:
  \begin{itemize}
    \item Filter out non-trivial obligations with automated provers
    \item Provide to a compiler for optimization purposes
    \item Debugging, program exploration
    \item Test generation/coverage reporting
    \item Early failure detection
    \item Generate runtime assertions
    \item <insert potential thesis topic here>
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Courting the Dynamic Language Crowd: Gradual Typing}

  Even bigger challenge: can we get dynamic language folks hooked on
  formal methods?
  \begin{itemize}
    \item Dynamic languages are popular because they are good for prototyping
    \item Upside: gets code out fast, reduce up-front cost
    \item Downside: (much) higher eventual cost
    \item Problem: you have to choose between lower up-front cost and
      lower eventual cost
    \item Currently a high barrier to transitioning a project to a
      more sustainable platform
    \item Embrace gradual typing in addition to gradual proving
    \item Goal: smooth transition from a prototype to a verified
      system, can stop at any point along the way
  \end{itemize}
\end{frame}

\section{Proof Automation}

\begin{frame}
  \frametitle{Table of Contents}
  \tableofcontents[currentsection]
\end{frame}

\begin{frame}
  \frametitle{Proof Scripting}
  \begin{itemize}
    \item Modern dependently-typed languages provide a proof scripting
      facility (Coq, Lean, etc.)
    \item Tend to be awkward, un-idiomatic for the language, also
      difficult to debug
    \item Working programmers dislike inconsistency and incoherence
  \end{itemize}
  How can we design a more practical proof-automation framework?
\end{frame}

\begin{frame}
  \frametitle{Preliminaries}
  \begin{itemize}
    \item Assume we have a Coq-like separation of types, values, and
      propositions
    \item \typekw{n}: Rank-$n$ type
    \item \propkw{}: Propositions
    \item ``Truth environment'' consists of propositions known to be true
    \item \truthkw{}: a \propkw{} in the truth environment
    \item We can compute over values, not over \typekw{n}s or
      \propkw{}s
    \item A proof obligation consists of a type environment, a truth
      environment and a goal (a \propkw)
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Proof Monad as a Managed Execution Environment}
  \begin{itemize}
    \item A ``proof monad'' (Kirchner, Mu\~{n}oz) is a managed
      execution environment for dispatching proof obligations
    \item Manages the goal(s) as well as the type and truth
      environments
    \item Provides the primitive proof rules (i.e. intuitionistic
      logic) as stateful operations that change the goal state, proof,
      and type environments in controlled ways
    \item Bad applications of primitive proof rules fail in some way
      (i.e. throw an exception)
    \item Programs running in a proof monad can only prove a valid
      \propkw{} or fail; managed environment prevents proving an
      invalid \propkw{}
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Proofs and Tactics in the Implementation Language}
  \begin{itemize}
    \item Provide a reflection API, which provides access to an
      AST-like structure for a given value (or type, prop, truth)
    \item $\operatorname{typeclass} \operatorname{reflect} a\; b$: ``I can
      reflect an $a$ as a $b$'', for reflection as ``nicer'' data
      structures.
    \item Reflecting \typekw{n}s and \propkw{}s gives a way to compute
      on them (with structural equality)
    \item Provide access to the goals and truth environment in a way
      that can guide computation through the reflection API
    \item We can then write proofs and tactics in the same language as
      implementations
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Importance of a Managed Environment}
  That we are running in a managed environment saves us from a
  circularity problem:
  \begin{itemize}
    \item Proofs/tactics written in the implementation language also
      give rise to proof obligations of their own
    \item If we prove the obligations for the proofs/tactics, then we
      know they \emph{always} produce a proof
    \item If we \emph{don't} prove them, then the proofs/tactics might
      fail unexpectedly, but the managed environment prevents them
      from producing an invalid proof
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Proof Automation Methodologies}
  \begin{itemize}
    \item Low-level proofs (apply, apply, rewrite,\ldots) are the
      equivalent of programming in assembly, tactics are the
      equivalent of functions
    \item Other extreme: ATP's, Chlipala's ``crush'' tactic
    \item Problem with ATP's: great when they work, trouble when they don't
    \item Can we find middle-ground that gives us the extensibility of
      automated proving, but with better failure modes?
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Decision Procedures and Transformers}
  \begin{itemize}
    \item Intuition: mathematical proofs often take the form of ``I
      have these preconditions and a term of this particular form''
    \item Tactics: ``go from a proposition of this exact structure and
      truths of this exact structure to propositions of this exact
      structure''; generalize this into ``goals of this \emph{general} form''
      (Lean, some advanced Coq tactics attempt to do this)
    \item Here are some possible idioms based on this idea:
      \begin{itemize}
        \item ``Recognizers'': function of the form $a \rightarrow
          \operatorname{bool}$ (where we have a $\operatorname{reflect}
          \operatorname{prop} a$ instance)
        \item ``Decision procedures'': solve a goal matched by a given
          recognizer, or else report errors conforming to a
          well-defined interface
        \item ``Transformers'': transform a goal matched by a
          recognizer into new goal(s) matching some recognizer(s)
        \item All these should provably terminate
      \end{itemize}
    \item Rationale: try to get away from rigid structural
      requirements, but make failures more informative
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{A Word on Termination}
  \begin{itemize}
    \item Termination proofs ``necessary'' for any code executed by
      the type/proof-checker (proofs, tactics, decision procedures, etc)
    \item In practice, we can adopt a ``shoot it down after 5
      seconds'' termination solution for unproven code
    \item Requiring termination proofs would be actively \emph{wrong}
      for many real applications (ex. servers, concurrency control, etc.)
    \item Also too strong for many theoretical guarantees (ex. lock-freedom)
    \item Solution: adopt lazy termination proof obligations (Weirich
      et al.), use timeouts for unproven code
  \end{itemize}
\end{frame}

\section{Language Features}

\begin{frame}
  \frametitle{Table of Contents}
  \tableofcontents[currentsection]
\end{frame}

\begin{frame}
  \frametitle{Languages at Scale}

  Industrial languages have to cope with stresses that emerge at large
  scales of code size, staff size, scope, and time
  \begin{itemize}
    \item Older languages lacked features for organizing code
      (classes, typeclasses, modules, etc); this limits the size of
      code that was feasible
    \item Object-Oriented popularized features that allowed better
      scaling
    \item OO features have since been decomposed, refined, and
      generalized (existential types, subtypes, etc), allowing other
      paradigms to scale well
    \item Question: what kinds of features would have the same effect
      on proofs and verified code?
    \item Question: how do we integrate with existing code
      organization paradigms?
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Dependent OO Classes}
  \begin{itemize}
    \item OO classes combine state management, encapsulation, and subtyping
    \item Separation logic, Hoare types can handle higher-order
      stateful computation (Ynot project)
    \item Abstract predicates: declare abstract properties, define
      meaning in implementations
    \item Specify behaviors in terms of abstract predicates
    \item Invariants: predicates preserved across all operations (more
      important when dealing with atomic concurrency)
    \item Every class has an implicit ``well-formed'' invariant can
      have others
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Dependent OO Classes (Example)}
  Example of a dependent OO class:
  \lstset{language=java, basicstyle=\ttfamily\scriptsize}
  \lstinputlisting{ooclass}
\end{frame}

\begin{frame}
  \frametitle{Dependent Typeclasses}
  \begin{itemize}
    \item Typeclasses generalize nicely to algebras (Ed Kmett)
    \item Add abstract properties, similar to dependent OO classes
    \item Laws: equivalences between expressions that must hold for
      implementations
    \item Should be able to mechanically transform OO classes with
      invariants into algebras (add this parameter, transform Hoare
      types)
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Dependent Typeclass (Example)}
  Example of a dependent typeclass:
  \lstset{language=haskell, basicstyle=\ttfamily\scriptsize}
  \lstinputlisting{typeclass}
\end{frame}

\begin{frame}
  \frametitle{Feature Idea for Abstracting Proofs: Theories}
  Theories:
  \begin{itemize}
    \item Model: concrete data structure definition
    \item Laws: concrete properties about the model that must hold
    \item Definitions and proofs: concrete definitions and proofs that
      will hold for all instances of the theory
  \end{itemize}
  Instances:
  \begin{itemize}
    \item Mapping from reflected terms of the instance type to the
      model type
    \item Proof that all laws hold
    \item Then you get all the definitions and proofs for free!
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Example of Theories}

  Example of a theory of maps:
  \lstset{language=haskell, basicstyle=\ttfamily\scriptsize}
  \lstinputlisting{theoryhead}
  We model maps as a history of all add/delete operations
\end{frame}

\begin{frame}
  \frametitle{Theory Instances}
  \begin{itemize}
    \item We need to map reflected terms of the instance type to the model
    \item We can also generate ``placeholders'': models arising from a
      given term, which we don't know anything about (yet)
    \item Placeholders are essentially existential variables indexed
      by a term
    \item We can prove equivalence of two placeholders by proving
      equivalence of their terms
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Example of a Theory Instance}

  For the instance, we map calls to the get and delete functions to
  the model, everything else to a placeholder
  \lstset{language=haskell, basicstyle=\ttfamily\scriptsize}
  \lstinputlisting{theoryinst}
  (Note: this shows why we want to reflect into nicer data structures!)
\end{frame}

\begin{frame}
  \frametitle{Modeling General Concurrency}
  \begin{itemize}
    \item Hoare types handle higher-order \emph{non-concurrent}
      stateful computation nicely; what about concurrency?
    \item Ownership types, etc good for lock-based, but what about
      lock-free concurrency?
    \item Answer: theories of execution traces!
    \item A specification gives one model of behavior; another is
      derived automatically from the implementation; obligation is to
      prove equivalence
    \item Different theories can give us different consistency
      (linearizability, serializability) and memory (TSO, PSO,
      causality, etc) models
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{A Model for Linearizable Concurrency}
  \begin{itemize}
    \item Atomic operations are Hoare-style pre/post-condition pairs
    \item Compose $\circ$, optimistic/pessimistic nondeterminism
      $\sqcup$/$\sqcap$, fixpoint operator $\mu x. f(x)$
    \item Under certain circumstances, we can apply \emph{reductions},
      which transform the behavior:
      \begin{itemize}
        \item At an encapsulation boundary (i.e. classes), we can
          discard internal concrete properties about state, retaining
          only abstract properties, then discard no-ops (this is what
          makes linearizable lock/wait-free data structures possible)
        \item Apply transforms from Lipton's Left/Right movers theory
          to reason about locks
        \item In purely sequential execution, reduce to a single
          Hoare-triple
      \end{itemize}
  \end{itemize}
\end{frame}

\section{Software Engineering Practice}

\begin{frame}
  \frametitle{Table of Contents}
  \tableofcontents[currentsection]
\end{frame}


\begin{frame}
  \frametitle{Software Engineering Questions}
  Many interesting questions arise regarding how to integrate
  formal methods into software engineering practice.
  \begin{itemize}
    \item Encourage a notion of ``maturity'' that includes detailed
      behavior specifications, verification of implementations,
      existence of proof automation, decision procedures, etc
    \item Open question: what sorts of design patterns lead to easy
      verification?
    \item How do we present these ideas in a way that's accessible to
     ``working programmers'' (hugely important)?
    \item Intuition: abstract algebra, particularly N\"{o}ther's
      theory of modules likely to be very useful
    \item What would happen if we turned good API designers loose on
      traditional mathematics?
  \end{itemize}
\end{frame}

\section{Conclusions, Future Work}

\begin{frame}
  \frametitle{Table of Contents}
  \tableofcontents[currentsection]
\end{frame}


\begin{frame}
  \frametitle{Conclusions}
  \begin{itemize}
    \item Very interesting possibilities for integrating industrial
      pragmatics with formal methods
    \item Key paradigm shifts: view dependent types as a built-in
      reasoning system, embrace gradualism, think in terms of
      cost/benefit tradeoffs
    \item Reflection and managed proof environment allow writing
      proofs and tactics in the implementation language
    \item Integrate dependent types into OO classes/typeclasses,
      theories for generalizing proofs
    \item A programming language embodying these ideas would be
      \emph{immensely} powerful
    \item Many open questions/opportunities
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{My Work}
  I have been pursuing work on this on my own for some time:
  \begin{itemize}
    \item Integration with industrial pragmatics grew out of
      experiences in OpenJDK, infosec world
    \item Recently began promoting ideas in the infosec world (good reception)
    \item Working on a programming language designed around these
      ideas (working name: salt)
    \item Salt language aims to be useful for low-level programming
      (kernel, lock-free concurrency, firmware)
    \item Also pursuing pure semantic theory work aimed at building a
      stronger connection to physical systems
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Let's Talk}

  There are a lot of open questions here, and the ideas need input;
  I'm happy to talk about ideas!
\end{frame}

\end{document}
